{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "according-general",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# data processing/manipulation\n",
    "pd.options.mode.chained_assignment = None\n",
    "import re\n",
    "\n",
    "# data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "# stopwords, tokenizer, stemmer\n",
    "import nltk  \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "# spell correction, lemmatization\n",
    "from textblob import TextBlob\n",
    "from textblob import Word\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "described-blood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "french-cologne",
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_df = pd.read_csv('hashtag_donaldtrump.csv', lineterminator='\\n')\n",
    "biden_df = pd.read_csv('hashtag_joebiden.csv', lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "medieval-pathology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unneeded columns\n",
    "trump_df = trump_df.drop(columns=['tweet_id','user_id','user_name','user_screen_name',\n",
    "                                  'user_description','user_join_date','collected_at'])\n",
    "biden_df = biden_df.drop(columns=['tweet_id','user_id','user_name','user_screen_name',\n",
    "                                  'user_description','user_join_date','collected_at'])\n",
    "\n",
    "# Renaming columns\n",
    "trump_df = trump_df.rename(columns={\"likes\": \"Likes\", \"retweet_count\": \"Retweets\", \n",
    "                                    \"state\": \"State\", \"user_followers_count\": \"Followers\"})\n",
    "biden_df = biden_df.rename(columns={\"likes\": \"Likes\", \"retweet_count\": \"Retweets\", \n",
    "                                    \"state\": \"State\", \"user_followers_count\": \"Followers\"})\n",
    "\n",
    "# Update United States country name for consistency\n",
    "d = {\"United States of America\":\"United States\"}\n",
    "trump_df['country'].replace(d, inplace=True)\n",
    "biden_df['country'].replace(d, inplace=True)\n",
    "\n",
    "trump_df = trump_df.loc[trump_df['country'] == \"United States\"]\n",
    "biden_df = biden_df.loc[biden_df['country'] == \"United States\"]\n",
    "\n",
    "# Drop null rows\n",
    "trump_df = trump_df.dropna()\n",
    "biden_df = biden_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "innocent-feelings",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = r'\\d+|http?\\S+|[^A-Za-z0-9]+'\n",
    "stop_words = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# Function to preprocess tweet \n",
    "def clean_tweet(tweet, stem=False, lemmatize=False):\n",
    "\n",
    "    # Make all text lowercase\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    # Remove links, special characters, punctuation, numbers, etc.\n",
    "    tweet = re.sub(to_remove, ' ', tweet)\n",
    "        \n",
    "    filtered_tweet = []\n",
    "    words = word_tokenize(tweet) \n",
    "\n",
    "    # Remove stopwords and stem\n",
    "    for word in words:\n",
    "        if not word in stop_words:\n",
    "            if stem:\n",
    "                filtered_tweet.append(ps.stem(word))\n",
    "            elif lemmatize:\n",
    "                filtered_tweet.append(Word(word).lemmatize())\n",
    "            else:\n",
    "                filtered_tweet.append(word)\n",
    "            \n",
    "    return filtered_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "changed-supervisor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trump_df['tweetNew'] = trump_df.tweet.apply(lambda x: clean_tweet(x))\n",
    "biden_df['tweetNew'] = biden_df.tweet.apply(lambda x: clean_tweet(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "allied-oliver",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(df):\n",
    "    \n",
    "    # Determine polarity and subjectivity\n",
    "    df['Polarity'] = df['tweetNew'].apply(lambda x: TextBlob(' '.join(x)).sentiment.polarity)\n",
    "    df['Subjectivity'] = df['tweetNew'].apply(lambda x: TextBlob(' '.join(x)).sentiment.subjectivity)\n",
    "    \n",
    "    # Classify overall sentiment\n",
    "    df.loc[df.Polarity > 0,'Sentiment'] = 1\n",
    "    df.loc[df.Polarity == 0,'Sentiment'] = 0\n",
    "    df.loc[df.Polarity < 0,'Sentiment'] = -1\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "alike-gardening",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "joe_tweet_senti = sentiment_analysis(biden_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "extended-pierce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>tweet</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>source</th>\n",
       "      <th>Followers</th>\n",
       "      <th>user_location</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>continent</th>\n",
       "      <th>State</th>\n",
       "      <th>state_code</th>\n",
       "      <th>tweetNew</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-10-15 00:00:25</td>\n",
       "      <td>In 2020, #NYPost is being #censorship #CENSORE...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1397.0</td>\n",
       "      <td>Chicago, Illinois</td>\n",
       "      <td>41.875562</td>\n",
       "      <td>-87.624421</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>IL</td>\n",
       "      <td>[nypost, censorship, censored, twitter, manipu...</td>\n",
       "      <td>-0.148810</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2020-10-15 00:01:23</td>\n",
       "      <td>Comments on this? \"Do Democrats Understand how...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>83.0</td>\n",
       "      <td>Tampa, Florida</td>\n",
       "      <td>27.947760</td>\n",
       "      <td>-82.458444</td>\n",
       "      <td>Tampa</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>Florida</td>\n",
       "      <td>FL</td>\n",
       "      <td>[comments, democrats, understand, ruthless, ch...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2020-10-15 00:01:47</td>\n",
       "      <td>Twitter is doing everything they can to help D...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Hollywood, FL</td>\n",
       "      <td>34.098003</td>\n",
       "      <td>-118.329523</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "      <td>[twitter, everything, help, democrats, win, el...</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.522222</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2020-10-15 00:01:57</td>\n",
       "      <td>@RealJamesWoods #BidenCrimeFamily #JoeBiden #H...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>34.053691</td>\n",
       "      <td>-118.242766</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "      <td>[realjameswoods, bidencrimefamily, joebiden, h...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2020-10-15 00:02:06</td>\n",
       "      <td>Come on @ABC PLEASE DO THE RIGHT THING. Move t...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>166.0</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>40.712728</td>\n",
       "      <td>-74.006015</td>\n",
       "      <td>New York</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>[come, abc, please, right, thing, move, biden,...</td>\n",
       "      <td>0.078571</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776836</th>\n",
       "      <td>2020-11-08 23:55:24</td>\n",
       "      <td>#Biden üóΩüá∫üá∏üëçüèΩ | Images üì∑ @ Santa Maria, CA.  | ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>8881.0</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>34.053691</td>\n",
       "      <td>-118.242766</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "      <td>[biden, images, santa, maria, ca, wethepeopleh...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776845</th>\n",
       "      <td>2020-11-08 23:56:15</td>\n",
       "      <td>Will #criticalRaceTheory become ubiquitous in ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>12606.0</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>39.952724</td>\n",
       "      <td>-75.163526</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>PA</td>\n",
       "      <td>[criticalracetheory, become, ubiquitous, biden...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776847</th>\n",
       "      <td>2020-11-08 23:56:21</td>\n",
       "      <td>You moving near #Biden ü§î https://t.co/1F6i1YIJ2P</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>803.0</td>\n",
       "      <td>Philadelphia PA</td>\n",
       "      <td>39.952724</td>\n",
       "      <td>-75.163526</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>PA</td>\n",
       "      <td>[moving, near, biden]</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776861</th>\n",
       "      <td>2020-11-08 23:58:09</td>\n",
       "      <td>#election #2020Elections #trump #biden https:/...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>New York, USA</td>\n",
       "      <td>40.712728</td>\n",
       "      <td>-74.006015</td>\n",
       "      <td>New York</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>[election, elections, trump, biden]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776865</th>\n",
       "      <td>2020-11-08 23:58:24</td>\n",
       "      <td>@FLOTUS I‚Äôm excited to have a FLOTUS whose vag...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>436.0</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>38.894992</td>\n",
       "      <td>-77.036558</td>\n",
       "      <td>Washington</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>DC</td>\n",
       "      <td>[flotus, excited, flotus, whose, vagina, seen,...</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90639 rows √ó 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 created_at  \\\n",
       "6       2020-10-15 00:00:25   \n",
       "17      2020-10-15 00:01:23   \n",
       "22      2020-10-15 00:01:47   \n",
       "25      2020-10-15 00:01:57   \n",
       "29      2020-10-15 00:02:06   \n",
       "...                     ...   \n",
       "776836  2020-11-08 23:55:24   \n",
       "776845  2020-11-08 23:56:15   \n",
       "776847  2020-11-08 23:56:21   \n",
       "776861  2020-11-08 23:58:09   \n",
       "776865  2020-11-08 23:58:24   \n",
       "\n",
       "                                                    tweet  Likes  Retweets  \\\n",
       "6       In 2020, #NYPost is being #censorship #CENSORE...    0.0       0.0   \n",
       "17      Comments on this? \"Do Democrats Understand how...    0.0       0.0   \n",
       "22      Twitter is doing everything they can to help D...    1.0       0.0   \n",
       "25      @RealJamesWoods #BidenCrimeFamily #JoeBiden #H...    0.0       0.0   \n",
       "29      Come on @ABC PLEASE DO THE RIGHT THING. Move t...    0.0       0.0   \n",
       "...                                                   ...    ...       ...   \n",
       "776836  #Biden üóΩüá∫üá∏üëçüèΩ | Images üì∑ @ Santa Maria, CA.  | ...    1.0       0.0   \n",
       "776845  Will #criticalRaceTheory become ubiquitous in ...    0.0       0.0   \n",
       "776847   You moving near #Biden ü§î https://t.co/1F6i1YIJ2P    0.0       0.0   \n",
       "776861  #election #2020Elections #trump #biden https:/...    0.0       0.0   \n",
       "776865  @FLOTUS I‚Äôm excited to have a FLOTUS whose vag...    0.0       0.0   \n",
       "\n",
       "                     source  Followers      user_location        lat  \\\n",
       "6        Twitter for iPhone     1397.0  Chicago, Illinois  41.875562   \n",
       "17          Twitter Web App       83.0     Tampa, Florida  27.947760   \n",
       "22       Twitter for iPhone        2.0      Hollywood, FL  34.098003   \n",
       "25      Twitter for Android       29.0    Los Angeles, CA  34.053691   \n",
       "29          Twitter Web App      166.0       New York, NY  40.712728   \n",
       "...                     ...        ...                ...        ...   \n",
       "776836   Twitter for iPhone     8881.0        LOS ANGELES  34.053691   \n",
       "776845      Twitter Web App    12606.0   Philadelphia, PA  39.952724   \n",
       "776847   Twitter for iPhone      803.0    Philadelphia PA  39.952724   \n",
       "776861   Twitter for iPhone     1092.0      New York, USA  40.712728   \n",
       "776865   Twitter for iPhone      436.0     Washington, DC  38.894992   \n",
       "\n",
       "              long          city        country      continent  \\\n",
       "6       -87.624421       Chicago  United States  North America   \n",
       "17      -82.458444         Tampa  United States  North America   \n",
       "22     -118.329523   Los Angeles  United States  North America   \n",
       "25     -118.242766   Los Angeles  United States  North America   \n",
       "29      -74.006015      New York  United States  North America   \n",
       "...            ...           ...            ...            ...   \n",
       "776836 -118.242766   Los Angeles  United States  North America   \n",
       "776845  -75.163526  Philadelphia  United States  North America   \n",
       "776847  -75.163526  Philadelphia  United States  North America   \n",
       "776861  -74.006015      New York  United States  North America   \n",
       "776865  -77.036558    Washington  United States  North America   \n",
       "\n",
       "                       State state_code  \\\n",
       "6                   Illinois         IL   \n",
       "17                   Florida         FL   \n",
       "22                California         CA   \n",
       "25                California         CA   \n",
       "29                  New York         NY   \n",
       "...                      ...        ...   \n",
       "776836            California         CA   \n",
       "776845          Pennsylvania         PA   \n",
       "776847          Pennsylvania         PA   \n",
       "776861              New York         NY   \n",
       "776865  District of Columbia         DC   \n",
       "\n",
       "                                                 tweetNew  Polarity  \\\n",
       "6       [nypost, censorship, censored, twitter, manipu... -0.148810   \n",
       "17      [comments, democrats, understand, ruthless, ch... -1.000000   \n",
       "22      [twitter, everything, help, democrats, win, el...  0.175000   \n",
       "25      [realjameswoods, bidencrimefamily, joebiden, h...  0.000000   \n",
       "29      [come, abc, please, right, thing, move, biden,...  0.078571   \n",
       "...                                                   ...       ...   \n",
       "776836  [biden, images, santa, maria, ca, wethepeopleh...  0.000000   \n",
       "776845  [criticalracetheory, become, ubiquitous, biden...  0.000000   \n",
       "776847                              [moving, near, biden]  0.100000   \n",
       "776861                [election, elections, trump, biden]  0.000000   \n",
       "776865  [flotus, excited, flotus, whose, vagina, seen,...  0.375000   \n",
       "\n",
       "        Subjectivity  Sentiment  \n",
       "6           0.678571       -1.0  \n",
       "17          1.000000       -1.0  \n",
       "22          0.522222        1.0  \n",
       "25          0.000000        0.0  \n",
       "29          0.178571        1.0  \n",
       "...              ...        ...  \n",
       "776836      0.000000        0.0  \n",
       "776845      0.000000        0.0  \n",
       "776847      0.400000        1.0  \n",
       "776861      0.000000        0.0  \n",
       "776865      0.750000        1.0  \n",
       "\n",
       "[90639 rows x 18 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joe_tweet_senti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "magnetic-coverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "through-terry",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=trump_df.tweetNew\n",
    "y=trump_df.Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "stylish-diagram",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 500\n",
    "tok = Tokenizer(num_words=2000)\n",
    "tok.fit_on_texts(X)\n",
    "sequences = tok.texts_to_sequences(X)\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "detailed-ecuador",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(sequences_matrix, y, test_size=0.3, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "nutritional-subscription",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorflow_based_model(): #Defined tensorflow_based_model function for training tenforflow based model\n",
    "    inputs = Input(name='inputs',shape=[max_len])#step1\n",
    "    layer = Embedding(2000,50,input_length=max_len)(inputs) #step2\n",
    "    layer = LSTM(64)(layer) #step3\n",
    "    layer = Dense(256,name='FC1')(layer) #step4\n",
    "    layer = Activation('relu')(layer) # step5\n",
    "    layer = Dropout(0.5)(layer) # step6\n",
    "    layer = Dense(1,name='out_layer')(layer) #step4 again but this time its giving only one output as because we need to classify the tweet as positive or negative\n",
    "    layer = Activation('sigmoid')(layer) #step5 but this time activation function is sigmoid for only one output.\n",
    "    model = Model(inputs=inputs,outputs=layer) #here we are getting the final output value in the model for classification\n",
    "    return model #function returning the value when we call it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "direct-peeing",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tensorflow_based_model() # here we are calling the function of created model\n",
    "model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "signed-terminology",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "803/803 [==============================] - 28s 31ms/step - loss: -12.2614 - accuracy: 0.5045 - val_loss: -229.0396 - val_accuracy: 0.5729\n",
      "Epoch 2/6\n",
      "803/803 [==============================] - 23s 29ms/step - loss: -383.0844 - accuracy: 0.5784 - val_loss: -1302.4216 - val_accuracy: 0.5642\n",
      "Epoch 3/6\n",
      "803/803 [==============================] - 23s 29ms/step - loss: -2105.0031 - accuracy: 0.6179 - val_loss: 1494.4022 - val_accuracy: 0.4657\n",
      "Epoch 4/6\n",
      "803/803 [==============================] - 24s 29ms/step - loss: -3913.1275 - accuracy: 0.6381 - val_loss: -8302.2617 - val_accuracy: 0.6759\n",
      "Epoch 5/6\n",
      "803/803 [==============================] - 24s 30ms/step - loss: -9420.3130 - accuracy: 0.6624 - val_loss: -13650.4521 - val_accuracy: 0.7014\n",
      "Epoch 6/6\n",
      "803/803 [==============================] - 24s 30ms/step - loss: -15443.8110 - accuracy: 0.6737 - val_loss: -21316.2617 - val_accuracy: 0.6947\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    history=model.fit(X_train,Y_train,batch_size=80,epochs=6, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "instrumental-roberts",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "956/956 [==============================] - 9s 9ms/step - loss: -20335.4414 - accuracy: 0.7030\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "closing-animation",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"final_df.csv\", thousands=',', decimal='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "collected-exchange",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rep2020</th>\n",
       "      <th>Rep2016</th>\n",
       "      <th>Less than a high school diploma, 2015-19</th>\n",
       "      <th>High school diploma only, 2015-19</th>\n",
       "      <th>Some college or associate's degree, 2015-19</th>\n",
       "      <th>Bachelor's degree or higher, 2015-19</th>\n",
       "      <th>Percent of adults with less than a high school diploma, 2015-19</th>\n",
       "      <th>Percent of adults with a high school diploma only, 2015-19</th>\n",
       "      <th>Percent of adults completing some college or associate's degree, 2015-19</th>\n",
       "      <th>Percent of adults with a bachelor's degree or higher, 2015-19</th>\n",
       "      <th>...</th>\n",
       "      <th>CI90UB517P_2019</th>\n",
       "      <th>MEDHHINC_2019</th>\n",
       "      <th>CI90LBINC_2019</th>\n",
       "      <th>CI90UBINC_2019</th>\n",
       "      <th>Civilian_labor_force_2019</th>\n",
       "      <th>Employed_2019</th>\n",
       "      <th>Unemployed_2019</th>\n",
       "      <th>Unemployment_rate_2019</th>\n",
       "      <th>Median_Household_Income_2019</th>\n",
       "      <th>Med_HH_Income_Percent_of_State_Total_2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4291</td>\n",
       "      <td>12551</td>\n",
       "      <td>10596</td>\n",
       "      <td>9929</td>\n",
       "      <td>11.5</td>\n",
       "      <td>33.6</td>\n",
       "      <td>28.4</td>\n",
       "      <td>26.6</td>\n",
       "      <td>...</td>\n",
       "      <td>19.4</td>\n",
       "      <td>58233</td>\n",
       "      <td>52517</td>\n",
       "      <td>63949</td>\n",
       "      <td>26172</td>\n",
       "      <td>25458</td>\n",
       "      <td>714</td>\n",
       "      <td>2.7</td>\n",
       "      <td>58233</td>\n",
       "      <td>112.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13893</td>\n",
       "      <td>41797</td>\n",
       "      <td>47274</td>\n",
       "      <td>48148</td>\n",
       "      <td>9.2</td>\n",
       "      <td>27.7</td>\n",
       "      <td>31.3</td>\n",
       "      <td>31.9</td>\n",
       "      <td>...</td>\n",
       "      <td>17.2</td>\n",
       "      <td>59871</td>\n",
       "      <td>54593</td>\n",
       "      <td>65149</td>\n",
       "      <td>97328</td>\n",
       "      <td>94675</td>\n",
       "      <td>2653</td>\n",
       "      <td>2.7</td>\n",
       "      <td>59871</td>\n",
       "      <td>115.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4812</td>\n",
       "      <td>6396</td>\n",
       "      <td>4676</td>\n",
       "      <td>2080</td>\n",
       "      <td>26.8</td>\n",
       "      <td>35.6</td>\n",
       "      <td>26.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>...</td>\n",
       "      <td>49.0</td>\n",
       "      <td>35972</td>\n",
       "      <td>31822</td>\n",
       "      <td>40122</td>\n",
       "      <td>8537</td>\n",
       "      <td>8213</td>\n",
       "      <td>324</td>\n",
       "      <td>3.8</td>\n",
       "      <td>35972</td>\n",
       "      <td>69.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3386</td>\n",
       "      <td>7256</td>\n",
       "      <td>3848</td>\n",
       "      <td>1678</td>\n",
       "      <td>20.9</td>\n",
       "      <td>44.9</td>\n",
       "      <td>23.8</td>\n",
       "      <td>10.4</td>\n",
       "      <td>...</td>\n",
       "      <td>32.7</td>\n",
       "      <td>47918</td>\n",
       "      <td>42291</td>\n",
       "      <td>53545</td>\n",
       "      <td>8685</td>\n",
       "      <td>8419</td>\n",
       "      <td>266</td>\n",
       "      <td>3.1</td>\n",
       "      <td>47918</td>\n",
       "      <td>92.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7763</td>\n",
       "      <td>13299</td>\n",
       "      <td>13519</td>\n",
       "      <td>5210</td>\n",
       "      <td>19.5</td>\n",
       "      <td>33.4</td>\n",
       "      <td>34.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>...</td>\n",
       "      <td>25.8</td>\n",
       "      <td>52902</td>\n",
       "      <td>46777</td>\n",
       "      <td>59027</td>\n",
       "      <td>25331</td>\n",
       "      <td>24655</td>\n",
       "      <td>676</td>\n",
       "      <td>2.7</td>\n",
       "      <td>52902</td>\n",
       "      <td>102.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56037</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>9239</td>\n",
       "      <td>10415</td>\n",
       "      <td>6291</td>\n",
       "      <td>7.2</td>\n",
       "      <td>33.0</td>\n",
       "      <td>37.2</td>\n",
       "      <td>22.5</td>\n",
       "      <td>...</td>\n",
       "      <td>11.1</td>\n",
       "      <td>80639</td>\n",
       "      <td>73437</td>\n",
       "      <td>87841</td>\n",
       "      <td>21274</td>\n",
       "      <td>20446</td>\n",
       "      <td>828</td>\n",
       "      <td>3.9</td>\n",
       "      <td>80639</td>\n",
       "      <td>121.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56039</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>834</td>\n",
       "      <td>2577</td>\n",
       "      <td>4037</td>\n",
       "      <td>9875</td>\n",
       "      <td>4.8</td>\n",
       "      <td>14.9</td>\n",
       "      <td>23.3</td>\n",
       "      <td>57.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.7</td>\n",
       "      <td>98837</td>\n",
       "      <td>86531</td>\n",
       "      <td>111143</td>\n",
       "      <td>15575</td>\n",
       "      <td>15151</td>\n",
       "      <td>424</td>\n",
       "      <td>2.7</td>\n",
       "      <td>98837</td>\n",
       "      <td>149.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56041</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>941</td>\n",
       "      <td>5383</td>\n",
       "      <td>4562</td>\n",
       "      <td>2078</td>\n",
       "      <td>7.3</td>\n",
       "      <td>41.5</td>\n",
       "      <td>35.2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.1</td>\n",
       "      <td>70756</td>\n",
       "      <td>63191</td>\n",
       "      <td>78321</td>\n",
       "      <td>9035</td>\n",
       "      <td>8682</td>\n",
       "      <td>353</td>\n",
       "      <td>3.9</td>\n",
       "      <td>70756</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56043</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>568</td>\n",
       "      <td>1650</td>\n",
       "      <td>2031</td>\n",
       "      <td>1297</td>\n",
       "      <td>10.2</td>\n",
       "      <td>29.8</td>\n",
       "      <td>36.6</td>\n",
       "      <td>23.4</td>\n",
       "      <td>...</td>\n",
       "      <td>17.4</td>\n",
       "      <td>55122</td>\n",
       "      <td>50050</td>\n",
       "      <td>60194</td>\n",
       "      <td>3941</td>\n",
       "      <td>3786</td>\n",
       "      <td>155</td>\n",
       "      <td>3.9</td>\n",
       "      <td>55122</td>\n",
       "      <td>83.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56045</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>323</td>\n",
       "      <td>1904</td>\n",
       "      <td>1844</td>\n",
       "      <td>1016</td>\n",
       "      <td>6.3</td>\n",
       "      <td>37.4</td>\n",
       "      <td>36.2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.7</td>\n",
       "      <td>59410</td>\n",
       "      <td>52275</td>\n",
       "      <td>66545</td>\n",
       "      <td>3811</td>\n",
       "      <td>3701</td>\n",
       "      <td>110</td>\n",
       "      <td>2.9</td>\n",
       "      <td>59410</td>\n",
       "      <td>89.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3111 rows √ó 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Rep2020  Rep2016  Less than a high school diploma, 2015-19  \\\n",
       "1001         1        1                                      4291   \n",
       "1003         1        1                                     13893   \n",
       "1005         1        1                                      4812   \n",
       "1007         1        1                                      3386   \n",
       "1009         1        1                                      7763   \n",
       "...        ...      ...                                       ...   \n",
       "56037        1        1                                      2017   \n",
       "56039        0        0                                       834   \n",
       "56041        1        1                                       941   \n",
       "56043        1        1                                       568   \n",
       "56045        1        1                                       323   \n",
       "\n",
       "       High school diploma only, 2015-19  \\\n",
       "1001                               12551   \n",
       "1003                               41797   \n",
       "1005                                6396   \n",
       "1007                                7256   \n",
       "1009                               13299   \n",
       "...                                  ...   \n",
       "56037                               9239   \n",
       "56039                               2577   \n",
       "56041                               5383   \n",
       "56043                               1650   \n",
       "56045                               1904   \n",
       "\n",
       "       Some college or associate's degree, 2015-19  \\\n",
       "1001                                         10596   \n",
       "1003                                         47274   \n",
       "1005                                          4676   \n",
       "1007                                          3848   \n",
       "1009                                         13519   \n",
       "...                                            ...   \n",
       "56037                                        10415   \n",
       "56039                                         4037   \n",
       "56041                                         4562   \n",
       "56043                                         2031   \n",
       "56045                                         1844   \n",
       "\n",
       "       Bachelor's degree or higher, 2015-19  \\\n",
       "1001                                   9929   \n",
       "1003                                  48148   \n",
       "1005                                   2080   \n",
       "1007                                   1678   \n",
       "1009                                   5210   \n",
       "...                                     ...   \n",
       "56037                                  6291   \n",
       "56039                                  9875   \n",
       "56041                                  2078   \n",
       "56043                                  1297   \n",
       "56045                                  1016   \n",
       "\n",
       "       Percent of adults with less than a high school diploma, 2015-19  \\\n",
       "1001                                                11.5                 \n",
       "1003                                                 9.2                 \n",
       "1005                                                26.8                 \n",
       "1007                                                20.9                 \n",
       "1009                                                19.5                 \n",
       "...                                                  ...                 \n",
       "56037                                                7.2                 \n",
       "56039                                                4.8                 \n",
       "56041                                                7.3                 \n",
       "56043                                               10.2                 \n",
       "56045                                                6.3                 \n",
       "\n",
       "       Percent of adults with a high school diploma only, 2015-19  \\\n",
       "1001                                                33.6            \n",
       "1003                                                27.7            \n",
       "1005                                                35.6            \n",
       "1007                                                44.9            \n",
       "1009                                                33.4            \n",
       "...                                                  ...            \n",
       "56037                                               33.0            \n",
       "56039                                               14.9            \n",
       "56041                                               41.5            \n",
       "56043                                               29.8            \n",
       "56045                                               37.4            \n",
       "\n",
       "       Percent of adults completing some college or associate's degree, 2015-19  \\\n",
       "1001                                                28.4                          \n",
       "1003                                                31.3                          \n",
       "1005                                                26.0                          \n",
       "1007                                                23.8                          \n",
       "1009                                                34.0                          \n",
       "...                                                  ...                          \n",
       "56037                                               37.2                          \n",
       "56039                                               23.3                          \n",
       "56041                                               35.2                          \n",
       "56043                                               36.6                          \n",
       "56045                                               36.2                          \n",
       "\n",
       "       Percent of adults with a bachelor's degree or higher, 2015-19  ...  \\\n",
       "1001                                                26.6              ...   \n",
       "1003                                                31.9              ...   \n",
       "1005                                                11.6              ...   \n",
       "1007                                                10.4              ...   \n",
       "1009                                                13.1              ...   \n",
       "...                                                  ...              ...   \n",
       "56037                                               22.5              ...   \n",
       "56039                                               57.0              ...   \n",
       "56041                                               16.0              ...   \n",
       "56043                                               23.4              ...   \n",
       "56045                                               20.0              ...   \n",
       "\n",
       "       CI90UB517P_2019  MEDHHINC_2019  CI90LBINC_2019  CI90UBINC_2019  \\\n",
       "1001              19.4          58233           52517           63949   \n",
       "1003              17.2          59871           54593           65149   \n",
       "1005              49.0          35972           31822           40122   \n",
       "1007              32.7          47918           42291           53545   \n",
       "1009              25.8          52902           46777           59027   \n",
       "...                ...            ...             ...             ...   \n",
       "56037             11.1          80639           73437           87841   \n",
       "56039              6.7          98837           86531          111143   \n",
       "56041             11.1          70756           63191           78321   \n",
       "56043             17.4          55122           50050           60194   \n",
       "56045             16.7          59410           52275           66545   \n",
       "\n",
       "       Civilian_labor_force_2019  Employed_2019  Unemployed_2019  \\\n",
       "1001                       26172          25458              714   \n",
       "1003                       97328          94675             2653   \n",
       "1005                        8537           8213              324   \n",
       "1007                        8685           8419              266   \n",
       "1009                       25331          24655              676   \n",
       "...                          ...            ...              ...   \n",
       "56037                      21274          20446              828   \n",
       "56039                      15575          15151              424   \n",
       "56041                       9035           8682              353   \n",
       "56043                       3941           3786              155   \n",
       "56045                       3811           3701              110   \n",
       "\n",
       "       Unemployment_rate_2019  Median_Household_Income_2019  \\\n",
       "1001                      2.7                         58233   \n",
       "1003                      2.7                         59871   \n",
       "1005                      3.8                         35972   \n",
       "1007                      3.1                         47918   \n",
       "1009                      2.7                         52902   \n",
       "...                       ...                           ...   \n",
       "56037                     3.9                         80639   \n",
       "56039                     2.7                         98837   \n",
       "56041                     3.9                         70756   \n",
       "56043                     3.9                         55122   \n",
       "56045                     2.9                         59410   \n",
       "\n",
       "       Med_HH_Income_Percent_of_State_Total_2019  \n",
       "1001                                       112.5  \n",
       "1003                                       115.6  \n",
       "1005                                        69.5  \n",
       "1007                                        92.6  \n",
       "1009                                       102.2  \n",
       "...                                          ...  \n",
       "56037                                      121.9  \n",
       "56039                                      149.4  \n",
       "56041                                      107.0  \n",
       "56043                                       83.3  \n",
       "56045                                       89.8  \n",
       "\n",
       "[3111 rows x 51 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "alpine-duncan",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data.index.name = None\n",
    "data.dropna(axis='columns',inplace=True)\n",
    "X = data.drop(['Rep2020'], axis = 1)\n",
    "Y = data[\"Rep2020\"]\n",
    "x_in, x_out, y_in, y_out = train_test_split(X, Y, test_size=0.25)\n",
    "sc = StandardScaler()\n",
    "x_in = sc.fit_transform(x_in)\n",
    "x_out = sc.transform(x_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "selective-valuation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "73/73 [==============================] - 1s 3ms/step - loss: 0.5857 - accuracy: 0.8208\n",
      "Epoch 2/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.5380 - accuracy: 0.8209\n",
      "Epoch 3/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4980 - accuracy: 0.8212\n",
      "Epoch 4/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.8315\n",
      "Epoch 5/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.8212\n",
      "Epoch 6/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4229 - accuracy: 0.8251\n",
      "Epoch 7/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.4160 - accuracy: 0.8164\n",
      "Epoch 8/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3924 - accuracy: 0.8261\n",
      "Epoch 9/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3742 - accuracy: 0.8309\n",
      "Epoch 10/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3749 - accuracy: 0.8299\n",
      "Epoch 11/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3695 - accuracy: 0.8211\n",
      "Epoch 12/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3484 - accuracy: 0.8338\n",
      "Epoch 13/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3389 - accuracy: 0.8321\n",
      "Epoch 14/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3434 - accuracy: 0.8223\n",
      "Epoch 15/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3309 - accuracy: 0.8309\n",
      "Epoch 16/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3350 - accuracy: 0.8169\n",
      "Epoch 17/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3266 - accuracy: 0.8171\n",
      "Epoch 18/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3103 - accuracy: 0.8317\n",
      "Epoch 19/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3002 - accuracy: 0.8364\n",
      "Epoch 20/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.3096 - accuracy: 0.8207\n",
      "Epoch 21/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2895 - accuracy: 0.8302\n",
      "Epoch 22/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2995 - accuracy: 0.8191\n",
      "Epoch 23/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2993 - accuracy: 0.8150\n",
      "Epoch 24/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2856 - accuracy: 0.8266\n",
      "Epoch 25/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2857 - accuracy: 0.8182\n",
      "Epoch 26/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2792 - accuracy: 0.8186\n",
      "Epoch 27/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2706 - accuracy: 0.8219\n",
      "Epoch 28/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2534 - accuracy: 0.8389\n",
      "Epoch 29/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2710 - accuracy: 0.8157\n",
      "Epoch 30/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2597 - accuracy: 0.8279\n",
      "Epoch 31/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2558 - accuracy: 0.8175\n",
      "Epoch 32/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.8240\n",
      "Epoch 33/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2384 - accuracy: 0.8265\n",
      "Epoch 34/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2397 - accuracy: 0.8255\n",
      "Epoch 35/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2351 - accuracy: 0.8227\n",
      "Epoch 36/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2276 - accuracy: 0.8255\n",
      "Epoch 37/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2241 - accuracy: 0.8242\n",
      "Epoch 38/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2129 - accuracy: 0.8275\n",
      "Epoch 39/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2182 - accuracy: 0.8314\n",
      "Epoch 40/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2197 - accuracy: 0.9081\n",
      "Epoch 41/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2173 - accuracy: 0.9272\n",
      "Epoch 42/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2153 - accuracy: 0.9481\n",
      "Epoch 43/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2094 - accuracy: 0.9539\n",
      "Epoch 44/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2039 - accuracy: 0.9680\n",
      "Epoch 45/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.2050 - accuracy: 0.9652\n",
      "Epoch 46/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.1891 - accuracy: 0.9759\n",
      "Epoch 47/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.1946 - accuracy: 0.9702\n",
      "Epoch 48/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.1968 - accuracy: 0.9657\n",
      "Epoch 49/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.1771 - accuracy: 0.9749\n",
      "Epoch 50/50\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.1912 - accuracy: 0.9725\n"
     ]
    }
   ],
   "source": [
    "# Set up layers \n",
    "inputs = Input(shape=(50,))\n",
    "x = Dense(1, activation='sigmoid')(inputs)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Set up model\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "with tf.device('/GPU:0'):\n",
    "    model.fit(x_in,y_in,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "lonely-superintendent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 2ms/step - loss: 0.1795 - accuracy: 0.9704\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    model.evaluate(x_out, y_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-value",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KERNEL_DISPLAY_NAME",
   "language": "python",
   "name": "environment_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
